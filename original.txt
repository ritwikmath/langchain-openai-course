Hi everyone, I'm Ritwik Math, and welcome to this tutorial on the basics of LangChain programming with practical examples using Open A-I and RAG.

Today, we're diving into LangChain, a framework designed to make building applications powered by large language models (LLMs) easier. It started as a single open-source project and has now grown into a full-fledged company. LangChain streamlines the entire development process for creating generative A-I applications. It offers solutions like open-source components, building blocks, third-party integrations, and tools like LangGraph and LangSmith, all of which create a robust ecosystem to help organizations develop ready-to-use LLM applications. In this video, though, we'll specifically focus on how LangChain integrates with Python. I am assuming that you are already familiar with Python and virtual environment. Let's get started!

In our first task, we will learn how to setup a LangChain project with Open A-I. Create a project folder and create a python virtual environment. Copy the python package names from description and copy it in requirements.txt file. In order to use OpenA-I api you have to create the API Key. If you have already exhausted the free limit, either create a new account or recharge your OpenA-I account. Copy the api key and paste it in the .e-n-v file. The environment variable name is OPENA-I_API_KEY. Activate the virtual environment you have just created and install all the packages.

Create a file named first_lesson.py. Import all these required packages. Call the load_dotenv() method. This will load the OPEN-A-I_API_KEY environment variable into the memory. It is needed for the OpenA-I package to call the OpenA-I apis. Lets create the model object that will be used to call the OpenA-I apis. Now let’s create a prompt template that will be passed to LLM for converting English to a language of user’s choice. A prompt template is a framework that uses a reusable structure and placeholders for dynamic content. In our prompt template, input and language are dynamic contents. Later we will convert this prompt template to prompt by providing specific values. A prompt is an input that we provide to an A-I Model to modify or guide the model behaviour, direct the model toward a specific task and get a particular response.Now let’s create a output parser to format the LLM output. Output parsers are responsible for formatting the output of an LLM model into a more suitable structure. There are many types of output parsers. We will convert the LLM model output to a string response so we have used StrOutputParser module. Other options are jsonoutput parser, pydantic parsers and more.
So, we have all the required objects, now let’s create a chain. Chain is a sequence of call that follows a specific pattern. LangChain now uses the LCEL or LangChain Expression Language to create the arbitrary custom chains. These chains are built on top of langChain’s Runnable protocol. Each runnable is a unit of work that can be invoked, batched, streamed, transformed and composed. We have use the pipe operator to chain runnable together.
Now the chain is ready, let’s invoke the chain. Remember, in our prompt template, we have input and language variables. In order to create prompt from the prompt template, we need to pass the dynamic contents. In the invoke method, we specify the values of input and language.

We had chosen string as the output parser, so we can direct print the response in console.
So this was the basic of LangChain with OpenA-I. LangChain abstracts the way LLM models works, so you can easily use Gemini or Mistral. Hope you have understood the concept of LangChain and see you in the next video.
